{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---[Using HuggingFace API]---\n",
      "gold: Book Flight\n",
      "pred: Book Plane.\n",
      "match: 78.49%\n",
      "\n",
      "gold: Book Flight\n",
      "pred: Book Airplane Reservation.\n",
      "match: 74.98%\n",
      "\n",
      "---[Using Local Embeddings]---\n",
      "gold: Book Flight\n",
      "pred: Book Plane.\n",
      "match: 78.49%\n",
      "\n",
      "gold: Book Flight\n",
      "pred: Book Airplane Reservation.\n",
      "match: 74.98%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "@dataclass\n",
    "class CosineSimilarity:\n",
    "    api_token: str\n",
    "    API_URL: str = \"https://api-inference.huggingface.co/models/sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "    def __post_init__( self ):\n",
    "        self.model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "    def headers(self) -> Dict[str, str]:\n",
    "        return {\"Authorization\": f\"Bearer {self.api_token}\"}\n",
    "\n",
    "    def query(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        response = requests.post(self.API_URL, headers=self.headers(), json=payload)\n",
    "        return response.json()\n",
    "\n",
    "    def get_similarity_score(self, gold_intent: str, pred_intent: str) -> float:\n",
    "        data = self.query(\n",
    "            {\n",
    "                \"inputs\": {\n",
    "                    \"source_sentence\": gold_intent,\n",
    "                    \"sentences\": [pred_intent]\n",
    "                }\n",
    "            })\n",
    "        return data[0]\n",
    "    \n",
    "    def get_cosine_similarity(self, gold_intent: str, pred_intent: str) -> float:\n",
    "\n",
    "        #Compute embedding for both lists\n",
    "        embedding_1 = self.model.encode( gold_intent, convert_to_tensor=True)\n",
    "        embedding_2 = self.model.encode( pred_intent, convert_to_tensor=True)\n",
    "        sim = util.pytorch_cos_sim(embedding_1, embedding_2).item()\n",
    "        return sim\n",
    "\n",
    "\n",
    "    def compare(self, gold_intent: str, pred_intent: str) -> None:\n",
    "        cosine_sim = round(self.get_similarity_score(gold_intent, pred_intent) * 100, 2)\n",
    "        print(f\"gold: {gold_intent}\\npred: {pred_intent}\\nmatch: {cosine_sim}%\\n\")\n",
    "\n",
    "    def compare_embed(self, gold_intent: str, pred_intent: str) -> None:\n",
    "        cosine_sim = round(self.get_cosine_similarity(gold_intent, pred_intent) * 100, 2)\n",
    "        print(f\"gold: {gold_intent}\\npred: {pred_intent}\\nmatch: {cosine_sim}%\\n\")\n",
    "\n",
    "print(\"---[Using HuggingFace API]---\")\n",
    "\n",
    "#Cosine Similarity Example\n",
    "similarity_checker = CosineSimilarity( api_token=\"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\" )\n",
    "similarity_checker.compare( \"Book Flight\", \"Book Plane.\" )\n",
    "similarity_checker.compare( \"Book Flight\", \"Book Airplane Reservation.\" )\n",
    "\n",
    "print(\"---[Using Local Embeddings]---\")\n",
    "\n",
    "#Embedding Similarity Example\n",
    "similarity_checker.compare_embed( \"Book Flight\", \"Book Plane.\" )\n",
    "similarity_checker.compare_embed( \"Book Flight\", \"Book Airplane Reservation.\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "@dataclass\n",
    "class EvaluationMetricsDemo:\n",
    "  pred_file: str\n",
    "  gold_file: str\n",
    "  embed_handler: CosineSimilarity \n",
    "\n",
    "  def is_match(self, gold_intent: str, pred_intent: list) -> bool:\n",
    "        return gold_intent == pred_intent\n",
    "    \n",
    "  def first_match(self, gold_intent: str, pred_intent: list) -> bool:\n",
    "     return gold_intent.split()[0] == pred_intent.split()[0]\n",
    "\n",
    "  def exist(self, gold_intent: str, pred_intent: list) -> bool:\n",
    "    return len( pred_intent ) > 0 and len( gold_intent ) > 0\n",
    "\n",
    "  def calculate_accuracy(self) -> None:\n",
    "    with open(self.pred_file, \"r\") as pred_f, open(self.gold_file, \"r\") as gold_f:\n",
    "      pred_lines = pred_f.readlines()\n",
    "      gold_lines = gold_f.readlines()\n",
    "      \n",
    "      assert len(pred_lines) == len(gold_lines)\n",
    "\n",
    "    total: float = 0.0\n",
    "    first_word_correct: float = 0.0\n",
    "    exact_match: float = 0.0\n",
    "\n",
    "    for pred_line, gold_line in zip(pred_lines, gold_lines):\n",
    "        if self.gold_file.endswith(\"json\"):\n",
    "            gold_intent = json.loads(gold_line)[\"translation\"][\"tgt\"]\n",
    "        else:\n",
    "            gold_intent = gold_line.strip()\n",
    "\n",
    "        pred_intent = pred_line.strip()\n",
    "    \n",
    "        total += 1.0\n",
    "        if self.first_match(gold_intent, pred_intent):\n",
    "            first_word_correct += 1.0\n",
    "        if self.exist( gold_intent, pred_intent ) and self.is_match( gold_intent, pred_intent ):\n",
    "            exact_match += 1.0\n",
    "\n",
    "    first_word_correct = round( first_word_correct / total * 100, 2 )\n",
    "    exact_match = round( exact_match / total * 100, 2 )\n",
    "\n",
    "    return first_word_correct, exact_match\n",
    "\n",
    "  def calculate_bleu_score(self) -> None:\n",
    "    smoothie = SmoothingFunction().method1 \n",
    "    with open(self.pred_file, \"r\") as pred_f, open(self.gold_file, \"r\") as gold_f:\n",
    "        pred_lines = pred_f.readlines()\n",
    "        gold_lines = gold_f.readlines()\n",
    "\n",
    "        assert len(pred_lines) == len(gold_lines)\n",
    "\n",
    "    total: float = 0.0\n",
    "    blue_scores: list = []\n",
    "\n",
    "    for pred_line, gold_line in zip(pred_lines, gold_lines):\n",
    "        if self.gold_file.endswith(\"json\"):\n",
    "            gold_intent = json.loads(gold_line)[\"translation\"][\"tgt\"]\n",
    "        else:\n",
    "            gold_intent = gold_line.strip()\n",
    "        pred_intent = pred_line.strip()\n",
    "\n",
    "        total += 1.0\n",
    "        reference = [gold_intent.split()]\n",
    "        hypothesis = pred_intent.split()\n",
    "        blue_scores.append(sentence_bleu(reference, hypothesis, smoothing_function=smoothie))\n",
    "\n",
    "    blue_score = sum(blue_scores) / total * 100\n",
    "    \n",
    "    return blue_score\n",
    "  \n",
    "  def jaccard_similarity(self, label1: str, label2: str) -> float:\n",
    "    # Tokenize the intent labels\n",
    "    tokens1 = set(label1.split())\n",
    "    tokens2 = set(label2.split())\n",
    "\n",
    "    # Calculate Jaccard similarity\n",
    "    intersection = len(tokens1.intersection(tokens2))\n",
    "    union = len(tokens1.union(tokens2))\n",
    "    similarity = intersection / union if union != 0 else 0.0\n",
    "\n",
    "    return similarity\n",
    "\n",
    "  def calculate_jaccard_similarity(self) -> None:\n",
    "    with open(self.pred_file, \"r\") as pred_f, open(self.gold_file, \"r\") as gold_f:\n",
    "        pred_lines = pred_f.readlines()\n",
    "        gold_lines = gold_f.readlines()\n",
    "\n",
    "        assert len(pred_lines) == len(gold_lines)\n",
    "\n",
    "    total: float = 0.0\n",
    "    jaccard_scores: list = []\n",
    "\n",
    "    for pred_line, gold_line in zip(pred_lines, gold_lines):\n",
    "        if self.gold_file.endswith(\"json\"):\n",
    "            gold_intent = json.loads(gold_line)[\"translation\"][\"tgt\"]\n",
    "        else:\n",
    "            gold_intent = gold_line.strip()\n",
    "        pred_intent = pred_line.strip()\n",
    "\n",
    "        total += 1.0\n",
    "        jaccard_scores.append( self.jaccard_similarity( gold_intent, pred_intent ) )\n",
    "\n",
    "    jaccard_score = sum(jaccard_scores) / total * 100\n",
    "    \n",
    "    return jaccard_score\n",
    "  \n",
    "  def cosine_similarity(self, label1: str, label2: str) -> float:\n",
    "    return self.embed_handler.get_cosine_similarity( label1, label2 )\n",
    "\n",
    "  def calculate_cosine_similarity(self) -> None:\n",
    "    with open(self.pred_file, \"r\") as pred_f, open(self.gold_file, \"r\") as gold_f:\n",
    "        pred_lines = pred_f.readlines()\n",
    "        gold_lines = gold_f.readlines()\n",
    "\n",
    "        assert len(pred_lines) == len(gold_lines)\n",
    "\n",
    "    cosine_scores: int = 0\n",
    "    total: float = 0.0\n",
    "\n",
    "    for pred_line, gold_line in zip(pred_lines, gold_lines):\n",
    "        if self.gold_file.endswith(\"json\"):\n",
    "            gold_intent = json.loads(gold_line)[\"translation\"][\"tgt\"]\n",
    "        else:\n",
    "            gold_intent = gold_line.strip()\n",
    "        pred_intent = pred_line.strip()\n",
    "        total += 1.0\n",
    "\n",
    "        score = self.cosine_similarity( gold_intent, pred_intent )\n",
    "        if score >= 0.70:\n",
    "            cosine_scores += 1\n",
    "\n",
    "    return cosine_scores / total\n",
    "    \n",
    "\n",
    "  def evaluate(self) -> dict:\n",
    "    accuracy = self.calculate_accuracy()\n",
    "    bleu_score = self.calculate_bleu_score()\n",
    "    jaccard_score = self.calculate_jaccard_similarity()\n",
    "    cosine_scores = self.calculate_cosine_similarity()\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy':  {\n",
    "            'first_word':  accuracy[0],\n",
    "            'exact_match': accuracy[1]\n",
    "        },\n",
    "        'bleu_score': bleu_score,\n",
    "        'jaccard_score': jaccard_score,\n",
    "        'cosine_similarity': cosine_scores\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': {'first_word': 98.86, 'exact_match': 98.86},\n",
       " 'bleu_score': 17.57956216781354,\n",
       " 'jaccard_score': 98.85714285714286,\n",
       " 'cosine_similarity': 0.9885714285714285}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = EvaluationMetricsDemo( \n",
    "    embed_handler=similarity_checker,\n",
    "    gold_file=\"results/Labels_gold_silver_model_3_1_full_resource.txt\",\n",
    "    pred_file=\"results/Preds_gold_silver_model_3_1_full_resource.txt\" )\n",
    "metrics.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Word Accuracy: 98.86%\n",
      "Exact Match Accuracy: 98.86%\n"
     ]
    }
   ],
   "source": [
    "first_word_correct, exact_match = metrics.calculate_accuracy()\n",
    "print( f\"First Word Accuracy: {first_word_correct}%\" )\n",
    "print( f\"Exact Match Accuracy: {exact_match}%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 17.57956216781354%\n"
     ]
    }
   ],
   "source": [
    "blue_score = metrics.calculate_bleu_score()\n",
    "print( f\"BLEU Score: {blue_score}%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Jaccard Similarity: 98.85714285714286%\n"
     ]
    }
   ],
   "source": [
    "avg_jaccard = metrics.calculate_jaccard_similarity()\n",
    "print( f\"Average Jaccard Similarity: {avg_jaccard}%\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Across All Files\n",
    "---\n",
    "Check accuracy across all n-shot settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Labels_gold_silver_model_2_eight_shot.txt and Preds_gold_silver_model_2_eight_shot.txt:\n",
      "{'accuracy': {'first_word': 90.71, 'exact_match': 88.86}, 'bleu_score': 36.46701448101957, 'jaccard_score': 89.22857142857151, 'cosine_similarity': 0.8885714285714286}\n",
      "\n",
      "\n",
      "Results for Labels_gold_silver_model_2_four_shot.txt and Preds_gold_silver_model_2_four_shot.txt:\n",
      "{'accuracy': {'first_word': 88.71, 'exact_match': 82.43}, 'bleu_score': 35.06086900567161, 'jaccard_score': 83.74047619047613, 'cosine_similarity': 0.8242857142857143}\n",
      "\n",
      "\n",
      "Results for Labels_gold_silver_model_2_full_resource.txt and Preds_gold_silver_model_2_full_resource.txt:\n",
      "{'accuracy': {'first_word': 98.0, 'exact_match': 96.71}, 'bleu_score': 40.82048378657413, 'jaccard_score': 96.97142857142863, 'cosine_similarity': 0.9671428571428572}\n",
      "\n",
      "\n",
      "Results for Labels_gold_silver_model_2_one_shot.txt and Preds_gold_silver_model_2_one_shot.txt:\n",
      "{'accuracy': {'first_word': 61.29, 'exact_match': 54.0}, 'bleu_score': 25.68582631106849, 'jaccard_score': 57.04523809523801, 'cosine_similarity': 0.5485714285714286}\n",
      "\n",
      "\n",
      "Results for Labels_gold_silver_model_2_sixteen_shot.txt and Preds_gold_silver_model_2_sixteen_shot.txt:\n",
      "{'accuracy': {'first_word': 97.29, 'exact_match': 94.71}, 'bleu_score': 39.80672740342876, 'jaccard_score': 95.22857142857153, 'cosine_similarity': 0.9471428571428572}\n",
      "\n",
      "\n",
      "Results for Labels_gold_silver_model_2_two_shot.txt and Preds_gold_silver_model_2_two_shot.txt:\n",
      "{'accuracy': {'first_word': 85.57, 'exact_match': 74.14}, 'bleu_score': 31.78664331601891, 'jaccard_score': 76.46666666666654, 'cosine_similarity': 0.7414285714285714}\n",
      "\n",
      "\n",
      "Results for Labels_gold_silver_model_3_1_eight_shot.txt and Preds_gold_silver_model_3_1_eight_shot.txt:\n",
      "{'accuracy': {'first_word': 95.29, 'exact_match': 91.86}, 'bleu_score': 38.57870077335184, 'jaccard_score': 92.54285714285729, 'cosine_similarity': 0.9185714285714286}\n",
      "\n",
      "\n",
      "Results for Labels_gold_silver_model_3_1_four_shot.txt and Preds_gold_silver_model_3_1_four_shot.txt:\n",
      "{'accuracy': {'first_word': 85.0, 'exact_match': 81.71}, 'bleu_score': 33.89011101184944, 'jaccard_score': 82.82857142857152, 'cosine_similarity': 0.8257142857142857}\n",
      "\n",
      "\n",
      "Results for Labels_gold_silver_model_3_1_full_resource.txt and Preds_gold_silver_model_3_1_full_resource.txt:\n",
      "{'accuracy': {'first_word': 98.57, 'exact_match': 96.71}, 'bleu_score': 40.77993336786933, 'jaccard_score': 97.08571428571437, 'cosine_similarity': 0.9671428571428572}\n",
      "\n",
      "\n",
      "Results for Labels_gold_silver_model_3_1_one_shot.txt and Preds_gold_silver_model_3_1_one_shot.txt:\n",
      "{'accuracy': {'first_word': 42.0, 'exact_match': 26.71}, 'bleu_score': 13.73965731926588, 'jaccard_score': 31.526190476190465, 'cosine_similarity': 0.2757142857142857}\n",
      "\n",
      "\n",
      "Results for Labels_gold_silver_model_3_1_sixteen_shot.txt and Preds_gold_silver_model_3_1_sixteen_shot.txt:\n",
      "{'accuracy': {'first_word': 96.57, 'exact_match': 93.86}, 'bleu_score': 39.516747657910486, 'jaccard_score': 94.40000000000013, 'cosine_similarity': 0.9385714285714286}\n",
      "\n",
      "\n",
      "Results for Labels_gold_silver_model_3_1_two_shot.txt and Preds_gold_silver_model_3_1_two_shot.txt:\n",
      "{'accuracy': {'first_word': 67.0, 'exact_match': 48.0}, 'bleu_score': 22.09986315378374, 'jaccard_score': 56.97857142857136, 'cosine_similarity': 0.5}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_results( path: str ) -> dict:\n",
    "    all_files = os.listdir( path )\n",
    "    labels = [ file for file in all_files if file.startswith( \"Labels\" ) ]\n",
    "    preds  = [ file.replace( \"Labels\", \"Preds\" ) for file in labels ]\n",
    "    for label, pred in zip( labels, preds ):\n",
    "        metrics = EvaluationMetricsDemo(\n",
    "                embed_handler=similarity_checker,\n",
    "                gold_file=f\"{path}/{label}\",\n",
    "                pred_file=f\"{path}/{pred}\"\n",
    "        )\n",
    "        results = metrics.evaluate()\n",
    "        print( f\"Results for {label} and {pred}:\" )\n",
    "        print( results )\n",
    "        print( \"\\n\" )\n",
    "        \n",
    "#get all folders under SNIPS\n",
    "folders = os.listdir( \"SNIPS\" )\n",
    "for folder in folders:\n",
    "    get_results( f\"SNIPS/{folder}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Play Music.', 'Get Weather.', 'Search Screening Event.', 'Book Restaurant.', 'Rate Book.', 'Search Creative Work.', 'Add To Playlist.'} {'Play Music.', 'ε', 'Get Weather.', 'Search Screening Event.', 'Book Restaurant.', 'Rate Book.', 'Search Creative Work.', 'Add To Playlist.'}\n",
      "Precisions:  [1.         1.         0.984375   0.66666667 1.         0.37219731\n",
      " 0.72881356 0.00625   ]\n",
      "Recalls:  [0.89 0.62 0.63 0.12 0.26 0.83 0.43 1.  ]\n",
      "F1 scores:  [0.94179894 0.7654321  0.76829268 0.20338983 0.41269841 0.51393189\n",
      " 0.5408805  0.01242236]\n",
      "<function confusion_matrix at 0x000002C1C6392290>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def load_intents_json(intents_file):\n",
    "    intents = []\n",
    "    with open(intents_file, 'r') as examples:\n",
    "        for example in examples:\n",
    "            data = json.loads(example)\n",
    "            intent = data[\"translation\"][\"tgt\"]\n",
    "            intents.append(intent)\n",
    "    return intents\n",
    "\n",
    "def load_intents_list(intents_file):\n",
    "    intents = []\n",
    "    with open(intents_file, 'r') as intent_preds:\n",
    "        for intent in intent_preds:\n",
    "            intents.append(intent.strip())\n",
    "    return intents\n",
    "\n",
    "\n",
    "confmat_name = \"snips\"\n",
    "\n",
    "true_intents = load_intents_list(\"SNIPS/model_2 results/Labels_gold_silver_model_2_one_shot.txt\")\n",
    "pred_intents = load_intents_list(\"SNIPS/model_2 results/Preds_gold_silver_model_2_one_shot.txt\")\n",
    "\n",
    "\n",
    "# replace all bad generated intents with BAD GENERATION\n",
    "intent_set = set(true_intents)\n",
    "for idx, pred in enumerate(pred_intents):\n",
    "    if pred not in intent_set:\n",
    "        pred_intents[idx] = \"ε\"\n",
    "\n",
    "# FOR DEBUGGING\n",
    "print(set(true_intents), set(pred_intents))\n",
    "for intent in set(true_intents):\n",
    "    if intent not in set(pred_intents):\n",
    "        pred_intents.append(intent)\n",
    "        true_intents.append(\"ε\")\n",
    "\n",
    "if \"ε\" not in set(true_intents):\n",
    "    true_intents.append(\"ε\")\n",
    "    pred_intents.append(\"ε\")\n",
    "\n",
    "precisions = defaultdict(list)\n",
    "recalls = defaultdict(list)\n",
    "f1s = defaultdict(list)\n",
    "precs, recs, f1s, supports = precision_recall_fscore_support(true_intents, pred_intents)\n",
    "\n",
    "print(\"Precisions: \", precs)\n",
    "print(\"Recalls: \", recs)\n",
    "print(\"F1 scores: \", f1s)\n",
    "\n",
    "# cmap = sns.color_palette(\"Reds\", 256)\n",
    "cmap = sns.color_palette(\"Blues\", 256)\n",
    "\n",
    "out_path = \"confmat_figures\"\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "#sns.set_context(\"paper\", rc={\"font.size\":18,\"axes.labelsize\":18})\n",
    "sns.set(font_scale = 1.0)\n",
    "\n",
    "data = confusion_matrix(true_intents, pred_intents)\n",
    "print(confusion_matrix)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(pred_intents), index=np.unique(true_intents))\n",
    "df_cm.index.name = \"True Intent\"\n",
    "df_cm.columns.name = \"Predicted Intent\"\n",
    "\n",
    "# non-normalized figure\n",
    "ax = sns.heatmap(df_cm, cmap=cmap, annot=False)\n",
    "ax.xaxis.tick_top() # x axis on top\n",
    "ax.xaxis.set_label_position('top')\n",
    "plt.xticks(rotation=45, ha='left')\n",
    "plt.savefig(os.path.join(out_path, f\"conf_mat_{confmat_name}_1shot.png\"), format=\"png\", \\\n",
    "    bbox_inches='tight', pad_inches=0.01)\n",
    "plt.cla(); plt.clf()\n",
    "\n",
    "# # normalized figure\n",
    "import numpy as np\n",
    "\n",
    "df_cmn = df_cm.astype('float') / np.array(df_cm.sum(axis=1))[:, np.newaxis]\n",
    "\n",
    "df_cmn.index.name = \"True Intent\"\n",
    "df_cmn.columns.name = \"Predicted Intent\"\n",
    "ax = sns.heatmap(df_cmn, cmap=cmap, annot=False, vmax=1.0)\n",
    "ax.xaxis.tick_top() # x axis on top\n",
    "ax.xaxis.set_label_position('top')\n",
    "ax.tick_params(left=True)\n",
    "plt.xticks(rotation=45, ha='left')\n",
    "plt.savefig(os.path.join(out_path, f\"conf_mat_{confmat_name}_1shot_norm.png\"), format=\"png\", \\\n",
    "    bbox_inches='tight', pad_inches=0.01)\n",
    "plt.cla(); plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
